{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71d1e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk(\"/kaggle/input\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.gridspec as grid_spec\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    f1_score,\n",
    ")\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "8cf933e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>126.46</td>\n",
       "      <td>14.3</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>214.77</td>\n",
       "      <td>15.0</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>63.98</td>\n",
       "      <td>15.1</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  age  hypertension  heart_disease ever_married      work_type  \\\n",
       "0    Male   82             0              1          Yes  Self-employed   \n",
       "1  Female   70             1              0          Yes        Private   \n",
       "2  Female   72             0              0          Yes        Private   \n",
       "\n",
       "  Residence_type  avg_glucose_level   bmi   smoking_status  stroke  \n",
       "0          Rural             126.46  14.3     never smoked     1.0  \n",
       "1          Urban             214.77  15.0  formerly smoked     0.0  \n",
       "2          Rural              63.98  15.1           smokes     1.0  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "be7ff6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                 0\n",
       "age                    0\n",
       "hypertension           0\n",
       "heart_disease          0\n",
       "ever_married           0\n",
       "work_type              0\n",
       "Residence_type         0\n",
       "avg_glucose_level      0\n",
       "bmi                  139\n",
       "smoking_status       138\n",
       "stroke                 1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "06433ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A really fantsatic and intelligent way to deal with blanks, from Thoman Konstantin in: https://www.kaggle.com/thomaskonstantin/analyzing-and-modeling-stroke-data\n",
    "\n",
    "DT_bmi_pipe = Pipeline(\n",
    "    steps=[(\"scale\", StandardScaler()), (\"lr\", DecisionTreeRegressor(random_state=42))]\n",
    ")\n",
    "X = df[[\"age\", \"gender\", \"bmi\"]].copy()\n",
    "X.gender = X.gender.replace({\"Male\": 0, \"Female\": 1, \"Other\": -1}).astype(np.uint8)\n",
    "\n",
    "Missing = X[X.bmi.isna()]\n",
    "X = X[~X.bmi.isna()]\n",
    "Y = X.pop(\"bmi\")\n",
    "DT_bmi_pipe.fit(X, Y)\n",
    "predicted_bmi = pd.Series(\n",
    "    DT_bmi_pipe.predict(Missing[[\"age\", \"gender\"]]), index=Missing.index\n",
    ")\n",
    "df.loc[Missing.index, \"bmi\"] = predicted_bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "963fe26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [variable for variable in df.columns if variable not in [\"stroke\"]]\n",
    "\n",
    "conts = [\"age\", \"avg_glucose_level\", \"bmi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "8ba23339",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_only = df[df[\"stroke\"] == 1]\n",
    "no_str_only = df[df[\"stroke\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "29e165fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"gender\"] = (\n",
    "    df[\"gender\"].replace({\"Male\": 0, \"Female\": 1, \"Other\": -1}).astype(np.uint8)\n",
    ")\n",
    "df[\"Residence_type\"] = (\n",
    "    df[\"Residence_type\"].replace({\"Rural\": 0, \"Urban\": 1}).astype(np.uint8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "26958c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse of Null Accuracy:  0.0487279843444227\n",
      "Null Accuracy:  0.9512720156555773\n"
     ]
    }
   ],
   "source": [
    "print(\"Inverse of Null Accuracy: \", 249 / (249 + 4861))\n",
    "print(\"Null Accuracy: \", 4861 / (4861 + 249))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "100b9e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"gender\", \"age\", \"hypertension\", \"heart_disease\", \"avg_glucose_level\", \"bmi\"]]\n",
    "y = df[\"stroke\"]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "879cb56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.62</td>\n",
       "      <td>29.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99.82</td>\n",
       "      <td>34.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  age  hypertension  heart_disease  avg_glucose_level   bmi\n",
       "1505       0   31             0              0             108.62  29.2\n",
       "2398       1   55             1              0              99.82  34.2"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "ff5e255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X_train_resh, y_train_resh = oversample.fit_resample(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "186af814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "\n",
    "# Scale our data in pipeline, then split\n",
    "\n",
    "rf_pipeline = Pipeline(\n",
    "    steps=[(\"scale\", StandardScaler()), (\"RF\", RandomForestClassifier(random_state=42))]\n",
    ")\n",
    "svm_pipeline = Pipeline(\n",
    "    steps=[(\"scale\", StandardScaler()), (\"SVM\", SVC(random_state=42))]\n",
    ")\n",
    "logreg_pipeline = Pipeline(\n",
    "    steps=[(\"scale\", StandardScaler()), (\"LR\", LogisticRegression(random_state=42))]\n",
    ")\n",
    "dt_pipeline = Pipeline(\n",
    "    steps=[(\"scale\", StandardScaler()), (\"DT\", DecisionTreeClassifier(random_state=42))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "acfa7d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv = cross_val_score(rf_pipeline, X_train_resh, y_train_resh, cv=10, scoring=\"f1\")\n",
    "svm_cv = cross_val_score(svm_pipeline, X_train_resh, y_train_resh, cv=10, scoring=\"f1\")\n",
    "logreg_cv = cross_val_score(\n",
    "    logreg_pipeline, X_train_resh, y_train_resh, cv=10, scoring=\"f1\"\n",
    ")\n",
    "dt_cv = cross_val_score(dt_pipeline, X_train_resh, y_train_resh, cv=10, scoring=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "5b8030d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f1 scores:\n",
      "Random Forest mean : 0.8479320320167847\n",
      "SVM mean : 0.7901025971057598\n",
      "Logistic Regression mean : 0.7941763000427062\n",
      "Decision Tree mean : 0.8101010299090584\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean f1 scores:\")\n",
    "print(\n",
    "    \"Random Forest mean :\",\n",
    "    cross_val_score(\n",
    "        rf_pipeline, X_train_resh, y_train_resh, cv=10, scoring=\"f1\"\n",
    "    ).mean(),\n",
    ")\n",
    "print(\n",
    "    \"SVM mean :\",\n",
    "    cross_val_score(\n",
    "        svm_pipeline, X_train_resh, y_train_resh, cv=10, scoring=\"f1\"\n",
    "    ).mean(),\n",
    ")\n",
    "print(\n",
    "    \"Logistic Regression mean :\",\n",
    "    cross_val_score(\n",
    "        logreg_pipeline, X_train_resh, y_train_resh, cv=10, scoring=\"f1\"\n",
    "    ).mean(),\n",
    ")\n",
    "print(\n",
    "    \"Decision Tree mean :\",\n",
    "    cross_val_score(\n",
    "        dt_pipeline, X_train_resh, y_train_resh, cv=10, scoring=\"f1\"\n",
    "    ).mean(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "9fc9bc75",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input y_true contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[253]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m logreg_pred = logreg_pipeline.predict(X_test)\n\u001b[32m      9\u001b[39m destree_pred = dt_pipeline.predict(X_test)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m rf_cm = \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrf_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m svm_cm = confusion_matrix(y_test, svm_pred)\n\u001b[32m     13\u001b[39m logreg_cm = confusion_matrix(y_test, logreg_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Dev v1.0\\Early-Stage-Brain-Stroke-Detection\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Dev v1.0\\Early-Stage-Brain-Stroke-Detection\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:340\u001b[39m, in \u001b[36mconfusion_matrix\u001b[39m\u001b[34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[32m    258\u001b[39m \n\u001b[32m    259\u001b[39m \u001b[33;03mBy definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    337\u001b[39m \u001b[33;03m(np.int64(0), np.int64(2), np.int64(1), np.int64(1))\u001b[39;00m\n\u001b[32m    338\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    339\u001b[39m y_true, y_pred = attach_unique(y_true, y_pred)\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m y_type, y_true, y_pred = \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    342\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m is not supported\u001b[39m\u001b[33m\"\u001b[39m % y_type)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Dev v1.0\\Early-Stage-Brain-Stroke-Detection\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99\u001b[39m, in \u001b[36m_check_targets\u001b[39m\u001b[34m(y_true, y_pred)\u001b[39m\n\u001b[32m     97\u001b[39m xp, _ = get_namespace(y_true, y_pred)\n\u001b[32m     98\u001b[39m check_consistent_length(y_true, y_pred)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m type_true = \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43my_true\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m type_pred = type_of_target(y_pred, input_name=\u001b[33m\"\u001b[39m\u001b[33my_pred\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    102\u001b[39m y_type = {type_true, type_pred}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Dev v1.0\\Early-Stage-Brain-Stroke-Detection\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:417\u001b[39m, in \u001b[36mtype_of_target\u001b[39m\u001b[34m(y, input_name, raise_unknown)\u001b[39m\n\u001b[32m    415\u001b[39m     data = y.data \u001b[38;5;28;01mif\u001b[39;00m issparse(y) \u001b[38;5;28;01melse\u001b[39;00m y\n\u001b[32m    416\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m xp.any(data != xp.astype(data, \u001b[38;5;28mint\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    418\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcontinuous\u001b[39m\u001b[33m\"\u001b[39m + suffix\n\u001b[32m    420\u001b[39m \u001b[38;5;66;03m# Check multiclass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Dev v1.0\\Early-Stage-Brain-Stroke-Detection\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Dev v1.0\\Early-Stage-Brain-Stroke-Detection\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input y_true contains NaN."
     ]
    }
   ],
   "source": [
    "rf_pipeline.fit(X_train_resh, y_train_resh)\n",
    "svm_pipeline.fit(X_train_resh, y_train_resh)\n",
    "logreg_pipeline.fit(X_train_resh, y_train_resh)\n",
    "dt_pipeline.fit(X_train_resh, y_train_resh)\n",
    "\n",
    "rf_pred = rf_pipeline.predict(X_test)\n",
    "svm_pred = svm_pipeline.predict(X_test)\n",
    "logreg_pred = logreg_pipeline.predict(X_test)\n",
    "destree_pred = dt_pipeline.predict(X_test)\n",
    "\n",
    "rf_cm = confusion_matrix(y_test, rf_pred)\n",
    "svm_cm = confusion_matrix(y_test, svm_pred)\n",
    "logreg_cm = confusion_matrix(y_test, logreg_pred)\n",
    "destree_cm = confusion_matrix(y_test, destree_pred)\n",
    "\n",
    "rf_f1 = f1_score(y_test, rf_pred)\n",
    "svm_f1 = f1_score(y_test, svm_pred)\n",
    "logreg_f1 = f1_score(y_test, logreg_pred)\n",
    "destree_f1 = f1_score(y_test, destree_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7079f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean f1 scores:\")\n",
    "\n",
    "print(\"RF mean :\", rf_f1)\n",
    "print(\"SVM mean :\", svm_f1)\n",
    "print(\"LR mean :\", logreg_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, rf_pred))\n",
    "\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b843b145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "n_estimators = [64, 100, 128, 200]\n",
    "max_features = [2, 3, 5, 7]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": n_estimators,\n",
    "    \"max_features\": max_features,\n",
    "    \"bootstrap\": bootstrap,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1180530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd51712",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(max_features=2, n_estimators=100, bootstrap=True)\n",
    "\n",
    "rfc.fit(X_train_resh, y_train_resh)\n",
    "\n",
    "rfc_tuned_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b4cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, rfc_tuned_pred))\n",
    "\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, rfc_tuned_pred))\n",
    "print(\"F1 Score: \", f1_score(y_test, rfc_tuned_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14830a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty = [\"l1\", \"l2\"]\n",
    "C = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "log_param_grid = {\"penalty\": penalty, \"C\": C}\n",
    "logreg = LogisticRegression()\n",
    "grid = GridSearchCV(logreg, log_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ac68e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use those params now\n",
    "\n",
    "logreg_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"scale\", StandardScaler()),\n",
    "        (\"LR\", LogisticRegression(C=0.1, penalty=\"l2\", random_state=42)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "logreg_pipeline.fit(X_train_resh, y_train_resh)\n",
    "\n",
    "# logreg.fit(X_train_resh,y_train_resh)\n",
    "\n",
    "logreg_tuned_pred = logreg_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293520cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, logreg_tuned_pred))\n",
    "\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, logreg_tuned_pred))\n",
    "print(\"F1 Score: \", f1_score(y_test, logreg_tuned_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c1c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import binarize\n",
    "\n",
    "for i in range(1, 6):\n",
    "    cm1 = 0\n",
    "    y_pred1 = logreg_pipeline.predict_proba(X_test)[:, 1]\n",
    "    y_pred1 = y_pred1.reshape(-1, 1)\n",
    "    y_pred2 = binarize(y_pred1, threshold=i / 10)\n",
    "    y_pred2 = np.where(y_pred2 == 1, 1, 0)\n",
    "    cm1 = confusion_matrix(y_test, y_pred2)\n",
    "\n",
    "    print(\n",
    "        \"With\",\n",
    "        i / 10,\n",
    "        \"threshold the Confusion Matrix is \",\n",
    "        \"\\n\\n\",\n",
    "        cm1,\n",
    "        \"\\n\\n\",\n",
    "        \"with\",\n",
    "        cm1[0, 0] + cm1[1, 1],\n",
    "        \"correct predictions, \",\n",
    "        \"\\n\\n\",\n",
    "        cm1[0, 1],\n",
    "        \"Type I errors( False Positives), \",\n",
    "        \"\\n\\n\",\n",
    "        cm1[1, 0],\n",
    "        \"Type II errors( False Negatives), \",\n",
    "        \"\\n\\n\",\n",
    "        \"Accuracy score: \",\n",
    "        (accuracy_score(y_test, y_pred2)),\n",
    "        \"\\n\\n\",\n",
    "        \"F1 score: \",\n",
    "        (f1_score(y_test, y_pred2)),\n",
    "        \"\\n\\n\",\n",
    "        \"Sensitivity: \",\n",
    "        cm1[1, 1] / (float(cm1[1, 1] + cm1[1, 0])),\n",
    "        \"\\n\\n\",\n",
    "        \"Specificity: \",\n",
    "        cm1[0, 0] / (float(cm1[0, 0] + cm1[0, 1])),\n",
    "        \"\\n\\n\",\n",
    "        \"====================================================\",\n",
    "        \"\\n\\n\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1928c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "lr_probs = logreg_pipeline.predict_proba(X_test)\n",
    "lr_probs = lr_probs[:, 1]\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "\n",
    "\n",
    "y_scores = logreg_pipeline.predict_proba(X_train)[:, 1]\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train, y_scores)\n",
    "\n",
    "\n",
    "# Plots\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "gs = fig.add_gridspec(1, 2, wspace=0.1, hspace=0)\n",
    "ax = gs.subplots()\n",
    "\n",
    "background_color = \"#f6f6f6\"\n",
    "fig.patch.set_facecolor(background_color)  # figure background color\n",
    "ax[0].set_facecolor(background_color)\n",
    "ax[1].set_facecolor(background_color)\n",
    "\n",
    "ax[0].grid(color=\"gray\", linestyle=\":\", axis=\"y\", zorder=0, dashes=(1, 5))\n",
    "ax[1].grid(color=\"gray\", linestyle=\":\", axis=\"y\", dashes=(1, 5))\n",
    "\n",
    "\n",
    "y_scores = logreg_pipeline.predict_proba(X_train)[:, 1]\n",
    "\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train, y_scores)\n",
    "\n",
    "ax[0].plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", color=\"#9bb7d4\")\n",
    "ax[0].plot(thresholds, recalls[:-1], \".\", linewidth=1, label=\"Recall\", color=\"#0f4c81\")\n",
    "ax[0].set_ylabel(\"True Positive Rate\", loc=\"bottom\")\n",
    "ax[0].set_xlabel(\"Thresholds\", loc=\"left\")\n",
    "# plt.legend(loc='center left')\n",
    "ax[0].set_ylim([0, 1])\n",
    "\n",
    "\n",
    "# plot the roc curve for the model\n",
    "ax[1].plot(ns_fpr, ns_tpr, linestyle=\"--\", label=\"Dummy Classifer\", color=\"gray\")\n",
    "ax[1].plot(lr_fpr, lr_tpr, marker=\".\", linewidth=2, color=\"#0f4c81\")\n",
    "ax[1].set_xlabel(\"False Positive Rate\", loc=\"left\")\n",
    "ax[1].set_ylabel(\"\")\n",
    "ax[1].set_ylim([0, 1])\n",
    "\n",
    "for s in [\"top\", \"right\", \"left\"]:\n",
    "    ax[0].spines[s].set_visible(False)\n",
    "    ax[1].spines[s].set_visible(False)\n",
    "\n",
    "\n",
    "ax[0].text(\n",
    "    -0.1,\n",
    "    2,\n",
    "    \"Model Selection: Considerations\",\n",
    "    fontsize=18,\n",
    "    fontfamily=\"serif\",\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "ax[0].text(\n",
    "    -0.1,\n",
    "    1.26,\n",
    "    \"\"\"\n",
    "Here we observe how our Logistic Regression model performs when we change the threshold.\n",
    "\n",
    "We'd like a model that predicts all strokes, but in reality, this would come at a cost.\n",
    "In fact we can create a model that succeeds in that goal, but it would mean predicting\n",
    "most people to have a stroke - which in itself would have negative effects.\n",
    "\n",
    "Therefore, we need to choose a model which not only predicts, correctly, those who have\n",
    "strokes, but also those who do not.\n",
    "\"\"\",\n",
    "    fontsize=14,\n",
    "    fontfamily=\"serif\",\n",
    ")\n",
    "\n",
    "\n",
    "ax[0].text(\n",
    "    -0.1, 1.1, \"Precision & Recall\", fontsize=14, fontfamily=\"serif\", fontweight=\"bold\"\n",
    ")\n",
    "ax[1].text(\n",
    "    -0.1,\n",
    "    1.1,\n",
    "    \"ROC: True Positives & False Positives\",\n",
    "    fontsize=14,\n",
    "    fontfamily=\"serif\",\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "ax[1].tick_params(axis=\"y\", colors=background_color)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ba40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df = pd.DataFrame(\n",
    "    data=[\n",
    "        f1_score(y_test, rf_pred),\n",
    "        accuracy_score(y_test, rf_pred),\n",
    "        recall_score(y_test, rf_pred),\n",
    "        precision_score(y_test, rf_pred),\n",
    "        roc_auc_score(y_test, rf_pred),\n",
    "    ],\n",
    "    columns=[\"Random Forest Score\"],\n",
    "    index=[\"F1\", \"Accuracy\", \"Recall\", \"Precision\", \"ROC AUC Score\"],\n",
    ")\n",
    "\n",
    "svm_df = pd.DataFrame(\n",
    "    data=[\n",
    "        f1_score(y_test, svm_pred),\n",
    "        accuracy_score(y_test, svm_pred),\n",
    "        recall_score(y_test, svm_pred),\n",
    "        precision_score(y_test, svm_pred),\n",
    "        roc_auc_score(y_test, svm_pred),\n",
    "    ],\n",
    "    columns=[\"Support Vector Machine (SVM) Score\"],\n",
    "    index=[\"F1\", \"Accuracy\", \"Recall\", \"Precision\", \"ROC AUC Score\"],\n",
    ")\n",
    "\n",
    "lr_df = pd.DataFrame(\n",
    "    data=[\n",
    "        f1_score(y_test, logreg_tuned_pred),\n",
    "        accuracy_score(y_test, logreg_tuned_pred),\n",
    "        recall_score(y_test, logreg_tuned_pred),\n",
    "        precision_score(y_test, logreg_tuned_pred),\n",
    "        roc_auc_score(y_test, logreg_tuned_pred),\n",
    "    ],\n",
    "    columns=[\"Tuned Logistic Regression Score\"],\n",
    "    index=[\"F1\", \"Accuracy\", \"Recall\", \"Precision\", \"ROC AUC Score\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26ae982",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models = round(pd.concat([rf_df, svm_df, lr_df], axis=1), 3)\n",
    "import matplotlib\n",
    "\n",
    "colors = [\"lightgray\", \"lightgray\", \"#0f4c81\"]\n",
    "colormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "\n",
    "background_color = \"#fbfbfb\"\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))  # create figure\n",
    "gs = fig.add_gridspec(4, 2)\n",
    "gs.update(wspace=0.1, hspace=0.5)\n",
    "ax0 = fig.add_subplot(gs[0, :])\n",
    "\n",
    "sns.heatmap(\n",
    "    df_models.T,\n",
    "    cmap=colormap,\n",
    "    annot=True,\n",
    "    fmt=\".1%\",\n",
    "    vmin=0,\n",
    "    vmax=0.95,\n",
    "    linewidths=2.5,\n",
    "    cbar=False,\n",
    "    ax=ax0,\n",
    "    annot_kws={\"fontsize\": 12},\n",
    ")\n",
    "fig.patch.set_facecolor(background_color)  # figure background color\n",
    "ax0.set_facecolor(background_color)\n",
    "\n",
    "ax0.text(\n",
    "    0, -2.15, \"Model Comparison\", fontsize=18, fontweight=\"bold\", fontfamily=\"serif\"\n",
    ")\n",
    "ax0.text(\n",
    "    0,\n",
    "    -0.9,\n",
    "    \"Random Forest performs the best for overall Accuracy,\\nbut is this enough? Is Recall more important in this case?\",\n",
    "    fontsize=14,\n",
    "    fontfamily=\"serif\",\n",
    ")\n",
    "ax0.tick_params(axis=\"both\", which=\"both\", length=0)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa0fca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting our results\n",
    "\n",
    "colors = [\n",
    "    \"lightgray\",\n",
    "    \"#0f4c81\",\n",
    "    \"#0f4c81\",\n",
    "    \"#0f4c81\",\n",
    "    \"#0f4c81\",\n",
    "    \"#0f4c81\",\n",
    "    \"#0f4c81\",\n",
    "    \"#0f4c81\",\n",
    "]\n",
    "colormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "\n",
    "\n",
    "background_color = \"#fbfbfb\"\n",
    "\n",
    "fig = plt.figure(figsize=(10, 14))  # create figure\n",
    "gs = fig.add_gridspec(4, 2)\n",
    "gs.update(wspace=0.1, hspace=0.8)\n",
    "ax0 = fig.add_subplot(gs[0, :])\n",
    "ax1 = fig.add_subplot(gs[1, :])\n",
    "ax2 = fig.add_subplot(gs[2, :])\n",
    "ax3 = fig.add_subplot(gs[3, :])\n",
    "ax0.set_facecolor(background_color)  # axes background color\n",
    "\n",
    "# Overall\n",
    "sns.heatmap(\n",
    "    rf_cm,\n",
    "    cmap=colormap,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    linewidths=5,\n",
    "    cbar=False,\n",
    "    ax=ax0,\n",
    "    yticklabels=[\"Actual Non-Stroke\", \"Actual Stroke\"],\n",
    "    xticklabels=[\"Predicted Non-Stroke\", \"Predicted Stroke\"],\n",
    "    annot_kws={\"fontsize\": 12},\n",
    ")\n",
    "\n",
    "sns.heatmap(\n",
    "    logreg_cm,\n",
    "    cmap=colormap,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    linewidths=5,\n",
    "    cbar=False,\n",
    "    ax=ax1,\n",
    "    yticklabels=[\"Actual Non-Stroke\", \"Actual Stroke\"],\n",
    "    xticklabels=[\"Predicted Non-Stroke\", \"Predicted Stroke\"],\n",
    "    annot_kws={\"fontsize\": 12},\n",
    ")\n",
    "\n",
    "sns.heatmap(\n",
    "    svm_cm,\n",
    "    cmap=colormap,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    linewidths=5,\n",
    "    cbar=False,\n",
    "    ax=ax2,\n",
    "    yticklabels=[\"Actual Non-Stroke\", \"Actual Stroke\"],\n",
    "    xticklabels=[\"Predicted Non-Stroke\", \"Predicted Stroke\"],\n",
    "    annot_kws={\"fontsize\": 12},\n",
    ")\n",
    "\n",
    "sns.heatmap(\n",
    "    destree_cm,\n",
    "    cmap=colormap,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    linewidths=5,\n",
    "    cbar=False,\n",
    "    ax=ax3,\n",
    "    yticklabels=[\"Actual Non-Stroke\", \"Actual Stroke\"],\n",
    "    xticklabels=[\"Predicted Non-Stroke\", \"Predicted Stroke\"],\n",
    "    annot_kws={\"fontsize\": 12},\n",
    ")\n",
    "\n",
    "\n",
    "ax0.tick_params(axis=\"both\", which=\"both\", length=0)\n",
    "background_color = \"#fbfbfb\"\n",
    "fig.patch.set_facecolor(background_color)  # figure background color\n",
    "ax0.set_facecolor(background_color)\n",
    "ax1.tick_params(axis=\"both\", which=\"both\", length=0)\n",
    "ax1.set_facecolor(background_color)\n",
    "ax2.tick_params(axis=\"both\", which=\"both\", length=0)\n",
    "ax2.set_facecolor(background_color)\n",
    "\n",
    "ax0.text(\n",
    "    0,\n",
    "    -0.75,\n",
    "    \"Random Forest Performance\",\n",
    "    fontsize=18,\n",
    "    fontweight=\"bold\",\n",
    "    fontfamily=\"serif\",\n",
    ")\n",
    "ax0.text(\n",
    "    0,\n",
    "    -0.2,\n",
    "    \"The model has the highest accuracy, and predicts non-Strokes well.\\nThe recall is poor though.\",\n",
    "    fontsize=14,\n",
    "    fontfamily=\"serif\",\n",
    ")\n",
    "\n",
    "ax1.text(\n",
    "    0,\n",
    "    -0.75,\n",
    "    \"Logistic Regression Performance\",\n",
    "    fontsize=18,\n",
    "    fontweight=\"bold\",\n",
    "    fontfamily=\"serif\",\n",
    ")\n",
    "ax1.text(\n",
    "    0,\n",
    "    -0.2,\n",
    "    \"This model predicts strokes with most success.\\nHowever, it gives a lot of false-positives.\",\n",
    "    fontsize=14,\n",
    "    fontfamily=\"serif\",\n",
    ")\n",
    "\n",
    "ax2.text(\n",
    "    0,\n",
    "    -0.75,\n",
    "    \"Support Vector Machine Performance\",\n",
    "    fontsize=18,\n",
    "    fontweight=\"bold\",\n",
    "    fontfamily=\"serif\",\n",
    ")\n",
    "ax2.text(\n",
    "    0,\n",
    "    -0.2,\n",
    "    \"A very similar performance to Logistic Regression.\\nThe recall is slightly less though.\",\n",
    "    fontsize=14,\n",
    "    fontfamily=\"serif\",\n",
    ")\n",
    "\n",
    "ax3.text(\n",
    "    0,\n",
    "    -0.75,\n",
    "    \"Decision Tree Performance\",\n",
    "    fontsize=18,\n",
    "    fontweight=\"bold\",\n",
    "    fontfamily=\"serif\",\n",
    ")\n",
    "ax3.text(\n",
    "    0,\n",
    "    -0.2,\n",
    "    \"A very similar performance to Logistic Regression.\\nThe recall is slightly less though.\",\n",
    "    fontsize=14,\n",
    "    fontfamily=\"serif\",\n",
    ")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb23e94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"lightgray\", \"lightgray\", \"#0f4c81\"]\n",
    "colormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "\n",
    "background_color = \"#fbfbfb\"\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))  # create figure\n",
    "gs = fig.add_gridspec(4, 2)\n",
    "gs.update(wspace=0.1, hspace=0.5)\n",
    "ax0 = fig.add_subplot(gs[0, :])\n",
    "ax1 = fig.add_subplot(gs[1, :])\n",
    "\n",
    "sns.heatmap(\n",
    "    lr_df.T,\n",
    "    cmap=colormap,\n",
    "    annot=True,\n",
    "    fmt=\".1%\",\n",
    "    vmin=0,\n",
    "    vmax=0.95,\n",
    "    yticklabels=\"\",\n",
    "    linewidths=2.5,\n",
    "    cbar=False,\n",
    "    ax=ax0,\n",
    "    annot_kws={\"fontsize\": 12},\n",
    ")\n",
    "fig.patch.set_facecolor(background_color)  # figure background color\n",
    "ax0.set_facecolor(background_color)\n",
    "ax1.set_facecolor(background_color)\n",
    "\n",
    "ax0.text(\n",
    "    0,\n",
    "    -2,\n",
    "    \"Tuned Logistic Regression Overview\",\n",
    "    fontsize=18,\n",
    "    fontweight=\"bold\",\n",
    "    fontfamily=\"serif\",\n",
    ")\n",
    "ax0.text(\n",
    "    0,\n",
    "    -0.3,\n",
    "    \"\"\"\n",
    "A reminder of the results that the tuned model acheived.\n",
    "The results are not perfect, but they do the best job at predicting those that will\n",
    "suffer a stroke without sacrificing overall accuracy too much.\n",
    "\n",
    "It has the highest f1 score of all models too - which is a weighted average of both\n",
    "precision and recall.\n",
    "\"\"\",\n",
    "    fontsize=14,\n",
    "    fontfamily=\"serif\",\n",
    ")\n",
    "ax0.tick_params(axis=\"both\", which=\"both\", length=0)\n",
    "\n",
    "\n",
    "# Overall\n",
    "\n",
    "sns.heatmap(\n",
    "    logreg_cm,\n",
    "    cmap=colormap,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    linewidths=5,\n",
    "    cbar=False,\n",
    "    ax=ax1,\n",
    "    yticklabels=[\"Actual Non-Stroke\", \"Actual Stroke\"],\n",
    "    vmax=500,\n",
    "    vmin=0,\n",
    "    xticklabels=[\"Predicted Non-Stroke\", \"Predicted Stroke\"],\n",
    "    annot_kws={\"fontsize\": 12},\n",
    ")\n",
    "ax0.tick_params(axis=\"both\", which=\"both\", length=0)\n",
    "ax1.tick_params(axis=\"both\", which=\"both\", length=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7229ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame(\n",
    "        {\"Feature\": df.columns, \"Importance\": m.feature_importances_}\n",
    "    ).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "\n",
    "fi = rf_feat_importance(rf_pipeline[\"RF\"], X)\n",
    "fi[:10].style.background_gradient(cmap=colormap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e69a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_color = \"#fbfbfb\"\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8), facecolor=background_color)\n",
    "\n",
    "color_map = [\"lightgray\" for _ in range(10)]\n",
    "color_map[0] = color_map[1] = color_map[2] = \"#0f4c81\"  # color highlight\n",
    "\n",
    "sns.barplot(data=fi, x=\"Importance\", y=\"Feature\", ax=ax, palette=color_map)\n",
    "ax.set_facecolor(background_color)\n",
    "for s in [\"top\", \"left\", \"right\"]:\n",
    "    ax.spines[s].set_visible(False)\n",
    "\n",
    "fig.text(\n",
    "    0.12,\n",
    "    0.92,\n",
    "    \"Feature Importance: Random Forest Stroke Prediction\",\n",
    "    fontsize=18,\n",
    "    fontweight=\"bold\",\n",
    "    fontfamily=\"serif\",\n",
    ")\n",
    "\n",
    "\n",
    "plt.xlabel(\" \", fontsize=12, fontweight=\"light\", fontfamily=\"serif\", loc=\"left\", y=-1.5)\n",
    "plt.ylabel(\" \", fontsize=12, fontweight=\"light\", fontfamily=\"serif\")\n",
    "\n",
    "\n",
    "fig.text(1.1, 0.92, \"Insight\", fontsize=18, fontweight=\"bold\", fontfamily=\"serif\")\n",
    "\n",
    "fig.text(\n",
    "    1.1,\n",
    "    0.315,\n",
    "    \"\"\"\n",
    "It is always interesting to view what features\n",
    "a predictive model utilises the most, that is, \n",
    "what features are the most important. \n",
    "This not only helps understand how the model\n",
    "works, but importantly can help us to explain\n",
    "the model results.\n",
    "\n",
    "In this case, we see that Age, Average Glucose Level,\n",
    "and BMI are the most important factors for our model.\n",
    "\n",
    "One also notices just how important Age is for our model,\n",
    "it is by far the most significant variable.\n",
    "\n",
    "It is also interesting that Work Type is more salient\n",
    "than Gender - this is a surprise.\n",
    "\n",
    "Having a history of Heart Disease and Hypertension\n",
    "are also low in the importance ranking which again\n",
    "is very surprising.\n",
    "\"\"\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"light\",\n",
    "    fontfamily=\"serif\",\n",
    ")\n",
    "\n",
    "ax.tick_params(axis=\"both\", which=\"both\", length=0)\n",
    "\n",
    "\n",
    "import matplotlib.lines as lines\n",
    "\n",
    "l1 = lines.Line2D(\n",
    "    [0.98, 0.98], [0, 1], transform=fig.transFigure, figure=fig, color=\"black\", lw=0.2\n",
    ")\n",
    "fig.lines.extend([l1])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949c7597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(rfc)\n",
    "\n",
    "# calculate shap values. This is what we will plot.\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42eb6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install lime\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "# LIME has one explainer for all the models\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    X.values,\n",
    "    feature_names=X.columns.values.tolist(),\n",
    "    class_names=[\"stroke\"],\n",
    "    verbose=True,\n",
    "    mode=\"classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f650da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "from IPython.display import display\n",
    "import webbrowser\n",
    "\n",
    "# Assume X and model pipeline are already defined\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=X.values,\n",
    "    feature_names=X.columns,\n",
    "    class_names=[\"no stroke\", \"stroke\"],\n",
    "    mode=\"classification\",\n",
    ")\n",
    "\n",
    "j = 2890  # instance index\n",
    "exp = explainer.explain_instance(\n",
    "    X.values[j], logreg_pipeline.predict_proba, num_features=10\n",
    ")\n",
    "\n",
    "exp.save_to_file(\"lime_explanation.html\")\n",
    "webbrowser.open(\"lime_explanation.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
